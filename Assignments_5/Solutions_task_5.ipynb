{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions Assignments 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "from pathlib import Path as P\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision as tv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec \n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import yaml\n",
    "\n",
    "import math\n",
    "\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_str, ActivationCountAnalysis\n",
    "\n",
    "import ipdb\n",
    "\n",
    "import inspect\n",
    "\n",
    "import torchgadgets as tg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/nfs/inf6/data/dataset/kth_actions'\n",
    "\n",
    "train = [11, 12, 13, 14, 15, 16, 17, 18]\n",
    "validation =[19, 20, 21, 23, 24, 25, 1, 4]\n",
    "test = [22, 2, 3, 5, 6, 7, 8, 9, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KTHAction_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_path, transform=None):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.processed_path = P(data_path) / 'processed'\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implementation of a LSTM/LSTM-Cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "        Implementation of a LSTM cell. For computational efficiency, we use a vectorized version of the implementation.\n",
    "        This reduces the number of matrix multiplication to two. All further values can be computed by taking slices of the so called Concatenated Gate Matrix.\n",
    "        Formulas:\n",
    "            A_t = W @ x_t + U @ h_{t-1} (Concatenated Gate Matrix)\n",
    "            i_t = sigmoid(A_t[:,0:hidden_size])\n",
    "            f_t = sigmoid(A_t[:,hidden_size:2*hidden_size])\n",
    "            o_t = sigmoid(A_t[:,2*hidden_size:3*hidden_size])\n",
    "            g_t = tanh(A_t[:,3*hidden_size:4*hidden_size])\n",
    "            c_t = f_t * c_{t-1} + i_t * g_t\n",
    "            h_t = o_t * tanh(c_t)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "            Initialize LSTM cell and all weights. The weights are also re-written in a vectorized variation.\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init_()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weights_ih = nn.Parameter(torch.Tensor(input_size, 4 * hidden_size))\n",
    "        self.weights_hh = nn.Parameter(torch.Tensor(hidden_size, 4 * hidden_size))\n",
    "        self.bias = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    \n",
    "    def forward(self, input:torch.Tensor, hidden_state = None):\n",
    "        \"\"\"\n",
    "            Forward pass of a single LSTM cell. We simply compute the formuals shown above.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(input.shape) == 1:\n",
    "            input = input.unsqueeze(0)\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        if hidden_state is None:\n",
    "            h_t, c_t = torch.zeros(batch_size, self.hidden_size), torch.zeros(batch_size, self.hidden_size)\n",
    "        else:\n",
    "            h_t, c_t = hidden_state\n",
    "        \n",
    "        A_t = torch.matmul(input, self.weights_ih) + torch.matmul(h_t, self.weights_hh) + self.bias\n",
    "        i_t = torch.sigmoid(A_t[:,0:self.hidden_size])\n",
    "        f_t = torch.sigmoid(A_t[:,self.hidden_size:2*self.hidden_size])\n",
    "        o_t = torch.sigmoid(A_t[:,2*self.hidden_size:3*self.hidden_size])\n",
    "        g_t = torch.tanh(A_t[:,3*self.hidden_size:4*self.hidden_size])\n",
    "        c_t = f_t * c_t + i_t * g_t\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "        return h_t, c_t\n",
    "        \n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"\n",
    "            This function was adapted from: https://github.com/pytorch/pytorch/\n",
    "            We followed this method as it seems a reasonable way of initializing the weights\n",
    "\n",
    "        \"\"\"\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size) if self.hidden_size > 0 else 0\n",
    "        for weight in self.parameters():\n",
    "            weight.uniform_(-stdv, stdv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
