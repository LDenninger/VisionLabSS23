{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Vision Sytems: Session 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today:\n",
    "\n",
    "### 1: Solution Assignment 6\n",
    "### 2: Deep Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seminar Vision Systems\n",
    "\n",
    " - https://www.ais.uni-bonn.de/SS23/4208_Sem_Vision_Systems.html\n",
    " - Introductory Meeting **today** after the lab, in the same room"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/seminar.png\" width=550><img src=\"./imgs/paper_list.png\" width=450>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Solution Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Deep Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and Loading Dataset\n",
    "mnist_tf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Pad(2),\n",
    "    ])\n",
    "\n",
    "# train + valid splits\n",
    "dataset = datasets.FashionMNIST(root='./data', train=True, transform=mnist_tf,download=True)\n",
    "train_img_dataset, val_img_dataset = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "\n",
    "# eval set\n",
    "test_img_dataset = datasets.FashionMNIST(root='./data', train=False, transform=mnist_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset:\n",
    "    \"\"\"\n",
    "    Dataset class from which we sample random triplets\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\" Dataset initializer\"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.arange = np.arange(len(dataset))\n",
    "        self.labels = torch.Tensor([l for _,l in dataset])\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\" Returning number of anchors \"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\" \n",
    "        Sampling a triplet for the dataset. Index i corresponds to anchor \n",
    "        \"\"\"\n",
    "        # sampling anchor\n",
    "        anchor_img, anchor_lbl = self.dataset[i]\n",
    "\n",
    "        # lists for positives and negatives\n",
    "        pos_ids = self.arange[torch.where(self.labels == anchor_lbl)]\n",
    "        neg_id = self.arange[torch.where(self.labels != anchor_lbl)]\n",
    "        \n",
    "        # random positive and negative\n",
    "        # BIG FLAW HERE! \n",
    "        pos_id, neg_id = random.choice(pos_ids).item(), random.choice(neg_id).item()  # BIG FLAW HERE! \n",
    "        pos_img, pos_lbl = self.dataset[pos_id] \n",
    "        neg_img, neg_lbl = self.dataset[neg_id]\n",
    "              \n",
    "        return (anchor_img, pos_img, neg_img), (anchor_lbl, pos_lbl, neg_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletDataset(train_img_dataset)\n",
    "val_dataset = TripletDataset(val_img_dataset)\n",
    "test_dataset = TripletDataset(test_img_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_anchors, anchors = plt.subplots(1, 10, figsize=(30,3))\n",
    "fig_pos, positives = plt.subplots(1, 10, figsize=(30,3))\n",
    "fig_neg, negatives = plt.subplots(1, 10, figsize=(30,3))\n",
    "for i in range(10):\n",
    "    (anchor, positive, negative), _ = val_dataset[i]\n",
    "    anchors[i].imshow(anchor[0], cmap=\"gray\")\n",
    "    anchors[i].axis(\"off\")\n",
    "    positives[i].imshow(positive[0], cmap=\"gray\")\n",
    "    positives[i].axis(\"off\")\n",
    "    negatives[i].imshow(negative[0], cmap=\"gray\")\n",
    "    negatives[i].axis(\"off\")\n",
    "fig_anchors.suptitle(\"Anchors\")\n",
    "fig_pos.suptitle(\"Positives\")\n",
    "fig_neg.suptitle(\"Negative\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True) \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=64, shuffle=True) \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "def smooth(f, K=5):\n",
    "    \"\"\" Smoothing a function using a low-pass filter (mean) of size K \"\"\"\n",
    "    kernel = np.ones(K) / K\n",
    "    f = np.concatenate([f[:int(K//2)], f, f[int(-K//2):]])  # to account for boundaries\n",
    "    smooth_f = np.convolve(f, kernel, mode=\"same\")\n",
    "    smooth_f = smooth_f[K//2: -K//2]  # removing boundary-fixes\n",
    "    return smooth_f\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, epoch, stats, margin):\n",
    "    \"\"\" Saving model checkpoint \"\"\"\n",
    "    \n",
    "    if(not os.path.exists(\"checkpoints\")):\n",
    "        os.makedirs(\"checkpoints\")\n",
    "    savepath = f\"checkpoints/checkpoint_epoch_{epoch}_margin_{margin}.pth\"\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'stats': stats\n",
    "    }, savepath)\n",
    "    return\n",
    "\n",
    "\n",
    "def load_model(model, optimizer, savepath):\n",
    "    \"\"\" Loading pretrained checkpoint \"\"\"\n",
    "    \n",
    "    checkpoint = torch.load(savepath, map_location=\"cpu\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    stats = checkpoint[\"stats\"]\n",
    "    \n",
    "    return model, optimizer, epoch, stats\n",
    "\n",
    "\n",
    "def count_model_params(model):\n",
    "    \"\"\" Counting the number of learnable parameters in a nn.Module \"\"\"\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return num_params\n",
    "\n",
    "def visualize_progress(train_loss, val_loss, start=0):\n",
    "    \"\"\" Visualizing loss and accuracy \"\"\"\n",
    "    fig, ax = plt.subplots(1,3)\n",
    "    fig.set_size_inches(24,5)\n",
    "\n",
    "    smooth_train = smooth(train_loss, 31)\n",
    "    ax[0].plot(train_loss, c=\"blue\", label=\"Loss\", linewidth=3, alpha=0.5)\n",
    "    ax[0].plot(smooth_train, c=\"red\", label=\"Smoothed Loss\", linewidth=3, alpha=1)\n",
    "    ax[0].legend(loc=\"best\")\n",
    "    ax[0].set_xlabel(\"Iteration\")\n",
    "    ax[0].set_ylabel(\"CE Loss\")\n",
    "    ax[0].set_yscale(\"linear\")\n",
    "    ax[0].set_title(\"Training Progress (linear)\")\n",
    "    \n",
    "    ax[1].plot(train_loss, c=\"blue\", label=\"Loss\", linewidth=3, alpha=0.5)\n",
    "    ax[1].plot(smooth_train, c=\"red\", label=\"Smoothed Loss\", linewidth=3, alpha=1)\n",
    "    ax[1].legend(loc=\"best\")\n",
    "    ax[1].set_xlabel(\"Iteration\")\n",
    "    ax[1].set_ylabel(\"CE Loss\")\n",
    "    ax[1].set_yscale(\"log\")\n",
    "    ax[1].set_title(\"Training Progress (log)\")\n",
    "\n",
    "    smooth_val = smooth(val_loss, 31)\n",
    "    N_ITERS = len(val_loss)\n",
    "    ax[2].plot(np.arange(start, N_ITERS)+start, val_loss[start:], c=\"blue\", label=\"Loss\", linewidth=3, alpha=0.5)\n",
    "    ax[2].plot(np.arange(start, N_ITERS)+start, smooth_val[start:], c=\"red\", label=\"Smoothed Loss\", linewidth=3, alpha=1)\n",
    "    ax[2].legend(loc=\"best\")\n",
    "    ax[2].set_xlabel(\"Iteration\")\n",
    "    ax[2].set_ylabel(\"CE Loss\")\n",
    "    ax[2].set_yscale(\"log\")\n",
    "    ax[2].set_title(f\"Valid Progress\")\n",
    "\n",
    "    return\n",
    "\n",
    "def display_projections(points, labels, ax=None, legend=None):\n",
    "    \"\"\" Displaying low-dimensional data projections \"\"\"\n",
    "    \n",
    "    COLORS = ['r', 'b', 'g', 'y', 'purple', 'orange', 'k', 'brown', 'grey',\n",
    "              'c', \"gold\", \"fuchsia\", \"lime\", \"darkred\", \"tomato\", \"navy\"]\n",
    "    \n",
    "    legend = [f\"Class {l}\" for l in np.unique(labels)] if legend is None else legend\n",
    "    if(ax is None):\n",
    "        _, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "    \n",
    "    for i,l in enumerate(np.unique(labels)):\n",
    "        idx = np.where(l==labels)\n",
    "\n",
    "        ax.scatter(points[idx, 0], points[idx, 1], label=legend[int(l)], c=COLORS[i])\n",
    "    ax.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormLayer(nn.Module):\n",
    "    \"\"\" Layer that computer embedding normalization \"\"\"\n",
    "    def __init__(self, l=2):\n",
    "        \"\"\" Layer initializer \"\"\"\n",
    "        assert l in [1, 2]\n",
    "        super().__init__()\n",
    "        self.l = l\n",
    "        return\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" Normalizing embeddings x. The shape of x is (B,D) \"\"\"\n",
    "        x_normalized = x / torch.norm(x, p=self.l, dim=-1, keepdim=True)\n",
    "        return x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\" Building block with 2 convolutions \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        \"\"\" \"\"\"\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" \"\"\"\n",
    "        y = self.block(x)\n",
    "        return y\n",
    "\n",
    "class SiameseModel(nn.Module):\n",
    "    \"\"\" \n",
    "    Implementation of a simple siamese model \n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dim=32, channels=[1, 32, 64, 128], in_spatial=(32, 32)):\n",
    "        \"\"\" Module initializer \"\"\"\n",
    "        super().__init__()\n",
    "        n_layers = len(channels) - 1\n",
    "        \n",
    "        # convolutional feature extractor\n",
    "        cnn = []\n",
    "        for i in range(n_layers):\n",
    "            cnn.append( ConvBlock(in_channels=channels[i], out_channels=channels[i+1], kernel_size=3) )\n",
    "        self.cnn = nn.Sequential(*cnn)\n",
    "        \n",
    "        # fully connected embedder\n",
    "        flat_dim = int(channels[-1] * (in_spatial[0] / (2**n_layers)) * (in_spatial[0] / (2**n_layers)))\n",
    "        self.fc = nn.Linear(flat_dim, emb_dim)\n",
    "        \n",
    "        # auxiliar layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.norm = NormLayer()\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def forward_one(self, x):\n",
    "        \"\"\" Forwarding just one sample through the model \"\"\"\n",
    "        x = self.cnn(x)\n",
    "        x_flat = self.flatten(x)\n",
    "        x_emb = self.fc(x_flat)\n",
    "        x_emb_norm = self.norm(x_emb)\n",
    "        return x_emb_norm\n",
    "    \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        \"\"\" Forwarding a triplet \"\"\"\n",
    "        anchor_emb = self.forward_one(anchor)\n",
    "        positive_emb = self.forward_one(positive)\n",
    "        negative_emb = self.forward_one(negative)\n",
    "        \n",
    "        # is there a more efficient way?\n",
    "        # imgs = torch.concat([anchor, positive, negative], dim=0)\n",
    "        # embs = self.forward_one(imgs)\n",
    "        # anchor_emb, positive_emb, negative_emb = torch.chunk(embs, 3, dim=0)\n",
    "        \n",
    "        return anchor_emb, positive_emb, negative_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model has {count_model_params(model)} parameters\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\" Implementation of the triplet loss function \"\"\"\n",
    "    def __init__(self, margin=0.2, reduce=\"mean\"):\n",
    "        \"\"\" Module initializer \"\"\"\n",
    "        assert reduce in [\"mean\", \"sum\"]\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.reduce = reduce\n",
    "        return\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        \"\"\" Computing pairwise distances and loss functions \"\"\"\n",
    "        # L2 distances\n",
    "        d_ap = (anchor - positive).pow(2).sum(dim=-1)\n",
    "        d_an = (anchor - negative).pow(2).sum(dim=-1)\n",
    "        \n",
    "        # triplet loss function\n",
    "        loss = (d_ap - d_an + self.margin)\n",
    "        loss = torch.maximum(loss, torch.zeros_like(loss))\n",
    "        \n",
    "        # averaging or summing      \n",
    "        loss = torch.mean(loss) if(self.reduce == \"mean\") else torch.sum(loss)\n",
    "      \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Class for training and validating a siamese model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, criterion, train_loader, valid_loader, n_iters=1e4):\n",
    "        \"\"\" Trainer initializer \"\"\"\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        \n",
    "        self.n_iters = int(n_iters)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "        return\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def valid_step(self, val_iters=100):\n",
    "        \"\"\" Some validation iterations \"\"\"\n",
    "        self.model.eval()\n",
    "        cur_losses = []\n",
    "        for i, ((anchors, positives, negatives),_) in enumerate(self.valid_loader):   \n",
    "            # setting inputs to GPU\n",
    "            anchors = anchors.to(self.device)\n",
    "            positives = positives.to(self.device)\n",
    "            negatives = negatives.to(self.device)\n",
    "            \n",
    "            # forward pass and triplet loss\n",
    "            anchor_emb, positive_emb, negative_emb = self.model(anchors, positives, negatives)\n",
    "            loss = self.criterion(anchor_emb, positive_emb, negative_emb)\n",
    "            cur_losses.append(loss.item())\n",
    "            \n",
    "            if(i >= val_iters):\n",
    "                break\n",
    "    \n",
    "        self.valid_loss += cur_losses\n",
    "        self.model.train()\n",
    "        \n",
    "        return cur_losses\n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\" Train/Validation loop \"\"\"\n",
    "    \n",
    "        self.iter_ = 0\n",
    "        progress_bar = tqdm(total=self.n_iters, initial=0)\n",
    "        \n",
    "        for i in range(self.n_iters):\n",
    "            for (anchors, positives, negatives), _ in self.train_loader:     \n",
    "                # setting inputs to GPU\n",
    "                anchors = anchors.to(self.device)\n",
    "                positives = positives.to(self.device)\n",
    "                negatives = negatives.to(self.device)\n",
    "                \n",
    "                # forward pass and triplet loss\n",
    "                anchor_emb, positive_emb, negative_emb = self.model(anchors, positives, negatives)\n",
    "                loss = self.criterion(anchor_emb, positive_emb, negative_emb)\n",
    "                self.train_loss.append(loss.item())\n",
    "                \n",
    "                # optimization\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "                # updating progress bar\n",
    "                progress_bar.set_description(f\"Train Iter {self.iter_}: Loss={round(loss.item(),5)})\")\n",
    "                \n",
    "                # doing some validation every once in a while\n",
    "                if(self.iter_ % 250 == 0):\n",
    "                    cur_losses = self.valid_step()\n",
    "                    print(f\"Valid loss @ iteration {self.iter_}: Loss={np.mean(cur_losses)}\")\n",
    "                \n",
    "                self.iter_ = self.iter_+1 \n",
    "                if(self.iter_ >= self.n_iters):\n",
    "                    break\n",
    "            if(self.iter_ >= self.n_iters):\n",
    "                break\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseModel()\n",
    "criterion = TripletLoss(margin=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, criterion=criterion, train_loader=train_loader, valid_loader=valid_loader, n_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_progress(trainer.train_loss, trainer.valid_loss, start=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    \"train_loss\": trainer.train_loss,\n",
    "    \"valid_loss\": trainer.valid_loss\n",
    "}\n",
    "save_model(trainer.model, trainer.optimizer, trainer.iter_, stats, margin=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a model trained for 10,000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, epoch, stats = load_model(trainer.model, trainer.optimizer, savepath=\"checkpoints/checkpoint_epoch_10000_margin_0.2.pth\")\n",
    "# model, optimizer, epoch, stats = load_model(trainer.model, trainer.optimizer, savepath=\"checkpoints/checkpoint_epoch_1000_margin_0.001.pth\")\n",
    "# model, optimizer, epoch, stats = load_model(trainer.model, trainer.optimizer, savepath=\"checkpoints/checkpoint_epoch_1000_margin_0.2.pth\")\n",
    "# model, optimizer, epoch, stats = load_model(trainer.model, trainer.optimizer, savepath=\"checkpoints/checkpoint_epoch_1000_margin_0.5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_progress(stats[\"train_loss\"], stats[\"valid_loss\"], start=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = trainer.model\n",
    "device = trainer.device\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img,_,_),(lbl,_,_) = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,10, figsize=(30,3))\n",
    "for i in range(10):\n",
    "    ax[i].imshow(img[i,0], cmap=\"gray\")\n",
    "    ax[i].set_title(lbl[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_flat = []\n",
    "embs = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for (anchor, _, _), (lbl,_, _) in test_loader:\n",
    "        anchor = anchor.to(device)\n",
    "        anchor_emb = model.forward_one(anchor)\n",
    "        \n",
    "        labels.append(lbl)\n",
    "        embs.append(anchor_emb.cpu())\n",
    "        imgs_flat.append(anchor.cpu().flatten(1))\n",
    "\n",
    "labels = np.concatenate(labels)\n",
    "embs = np.concatenate(embs)\n",
    "imgs_flat = np.concatenate(imgs_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_imgs = PCA(n_components=2).fit_transform(imgs_flat)\n",
    "pca_embs = PCA(n_components=2).fit_transform(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "plt.style.use('seaborn-v0_8')\n",
    "fig,ax = plt.subplots(1,2,figsize=(26,8))\n",
    "display_projections(pca_imgs[:N], labels[:N], ax=ax[0], legend=test_dataset.dataset.classes)\n",
    "ax[0].set_title(\"PCA Proj. of Images\")\n",
    "display_projections(pca_embs[:N], labels[:N], ax=ax[1], legend=test_dataset.dataset.classes)\n",
    "ax[1].set_title(\"PCA Proj. of Embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "tsne_imgs = TSNE(n_components=2).fit_transform(imgs_flat[:N])\n",
    "tsne_embs = TSNE(n_components=2).fit_transform(embs[:N])\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(26,8))\n",
    "display_projections(tsne_imgs[:N], labels[:N], ax=ax[0], legend=test_dataset.dataset.classes)\n",
    "ax[0].set_title(\"T-SNE Proj. of Images\")\n",
    "display_projections(tsne_embs[:N], labels[:N], ax=ax[1], legend=test_dataset.dataset.classes)\n",
    "ax[1].set_title(\"T-SNE Proj. of Embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_imgs = KMeans(n_clusters=10, random_state=0).fit(imgs_flat)\n",
    "kmeans_embs = KMeans(n_clusters=10, random_state=0).fit(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_imgs = adjusted_rand_score(labels, kmeans_imgs.labels_)\n",
    "ari_embs = adjusted_rand_score(labels, kmeans_embs.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Clustering images achieves  ARI={round(ari_imgs*100,2)}%\")\n",
    "print(f\"Clustering embeddings achieves ARI={round(ari_embs*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Compression ratio: {embs.shape[-1]}/{imgs_flat.shape[-1]}  = {round(embs.shape[-1]/imgs_flat.shape[-1] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When clustering using the latent codes from an autoencoder, we achieved a 37% accuracy. However, today we double that performance.\n",
    "\n",
    "#### Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_projections_images(points, labels, dataset, ax=None, legend=None):\n",
    "    \"\"\" Displaying low-dimensional data projections using images instead of points \"\"\"\n",
    "    from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "    COLORS = ['r', 'b', 'g', 'y', 'purple', 'orange', 'k', 'brown', 'grey',\n",
    "              'c', \"gold\", \"fuchsia\", \"lime\", \"darkred\", \"tomato\", \"navy\"]\n",
    "    \n",
    "    legend = [f\"Class {l}\" for l in np.unique(labels)] if legend is None else legend\n",
    "    _, ax = plt.subplots(1,1,figsize=(36,24))\n",
    "    \n",
    "    for l in np.unique(labels):\n",
    "        idx = np.where(l==labels)\n",
    "        ax.scatter(points[idx, 0], points[idx, 1], label=legend[int(l)], color=COLORS[l]) \n",
    "\n",
    "    for i, point in enumerate(points):\n",
    "        xy = [point[0], point[1]]\n",
    "        \n",
    "        arr_img = dataset[i][0][0][0]\n",
    "        l = labels[i]\n",
    "        imagebox = OffsetImage(arr_img, zoom=1)\n",
    "        imagebox.image.axes = ax\n",
    "        ab = AnnotationBbox(imagebox, xy,\n",
    "                            xybox=(0, 0),\n",
    "                            xycoords='data',\n",
    "                            boxcoords=\"offset points\",\n",
    "                            pad=0.1,\n",
    "                            bboxprops=dict(edgecolor=COLORS[l], lw=2)\n",
    "                            )\n",
    "\n",
    "        ax.add_artist(ab)\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_projections_images(points=tsne_embs[:2000], labels=labels[:2000], dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "\n",
    " - Implement the (adapted) TriNet Siamese model:\n",
    "    - Resnet18 convolutional backbone (until AvgPool) \n",
    "    - Fully connected frontend to obtain desired embedding\n",
    "    - Normalization layer\n",
    " - Use *Market-1501* dataset (https://zheng-lab.cecs.anu.edu.au/Project/project_reid.html)\n",
    "    - Around 33k bounding-box crops\n",
    "    - Train and test set\n",
    " - Train the following models:\n",
    "    - TriNet initialized with random weights\n",
    "    - Fine-tuned TriNet (pretrained ResNet and then fine-tuned)\n",
    "    - The best of the above models, but using semi-hard negative mining strategy (https://arxiv.org/abs/1503.03832)\n",
    " - Evaluate and compare the model performance (need not be thorough)\n",
    " - Visualize embeddings (not necessarly for all classes)\n",
    " - **Extra Point**: Train the same model as before, but with the following loss functions, and compare the results:\n",
    "     - Angular Loss (https://arxiv.org/abs/1708.01682)\n",
    "     - N-Pair Loss (https://papers.nips.cc/paper/2016/hash/6b180037abbebea991d8b1232f8a8ca9-Abstract.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Due Date**: No later than July 11 2023\n",
    "#### Submit it by mail using the subject: **CudaLab: Assignment7 + Group Name**\n",
    "####  Send me the following: Jupyter Notebook after running, Jupyter export as **html**, any other .py files or images used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    " - https://www.deeplearningbook.org/\n",
    " - https://towardsdatascience.com/all-you-want-to-know-about-deep-learning-8d68dcffc258\n",
    " - https://www.youtube.com/watch?v=6e65XfwmIWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=alert style=\"background-color:#F5F5F5; border-color:#C8C8C8\">\n",
    "    <b>Simon Bultmann</b><br>\n",
    "    <ul>\n",
    "       <li> <b>Email</b>: bultmann@ais.uni-bonn.de\n",
    "       <li> <b>Website</b>: https://www.ais.uni-bonn.de/~sbultmann/\n",
    "    </ul>\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
